{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca4b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\aksha\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 22.2.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import (LSTM, Embedding, BatchNormalization, Dense, TimeDistributed, Dropout, Bidirectional, Flatten, GlobalMaxPool1D)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    classification_report,\n",
    "    accuracy_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591b616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "7532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "print(len(train.data))\n",
    "print(len(test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e81170b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing all the categories\n",
    "train.target_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90590f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19]),\n",
       " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
       "        594, 593, 599, 546, 564, 465, 377], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding frequency of each category\n",
    "targets, frequency = np.unique(train.target, return_counts=True)\n",
    "targets, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b41518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n"
     ]
    }
   ],
   "source": [
    "targets_str = np.array(train.target_names)\n",
    "print(list(zip(targets_str, frequency)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dedad2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target\n",
       "0  I was wondering if anyone out there could enli...       7\n",
       "1  A fair number of brave souls who upgraded thei...       4\n",
       "2  well folks, my mac plus finally gave up the gh...       4\n",
       "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = pd.DataFrame({'data': train.data, 'target': train.target})\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f304e57",
   "metadata": {},
   "source": [
    "Formatting Test Data using the same steps as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9824c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46eb5b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19]),\n",
       " array([319, 389, 394, 392, 385, 395, 390, 396, 398, 397, 399, 396, 393,\n",
       "        396, 394, 398, 364, 376, 310, 251], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding frequency of each category\n",
    "targets_test, frequency_test = np.unique(test.target, return_counts=True)\n",
    "targets_test, frequency_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb23065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alt.atheism', 319), ('comp.graphics', 389), ('comp.os.ms-windows.misc', 394), ('comp.sys.ibm.pc.hardware', 392), ('comp.sys.mac.hardware', 385), ('comp.windows.x', 395), ('misc.forsale', 390), ('rec.autos', 396), ('rec.motorcycles', 398), ('rec.sport.baseball', 397), ('rec.sport.hockey', 399), ('sci.crypt', 396), ('sci.electronics', 393), ('sci.med', 396), ('sci.space', 394), ('soc.religion.christian', 398), ('talk.politics.guns', 364), ('talk.politics.mideast', 376), ('talk.politics.misc', 310), ('talk.religion.misc', 251)]\n"
     ]
    }
   ],
   "source": [
    "target_test_str = np.array(test.target_names)\n",
    "print(list(zip(target_test_str, frequency_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe687aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIn a word, yes.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target\n",
       "0  I am a little confused on all of the models of...       7\n",
       "1  I'm not familiar at all with the format of the...       5\n",
       "2                                \\nIn a word, yes.\\n       0\n",
       "3  \\nThey were attacking the Iraqis to drive them...      17\n",
       "4  \\nI've just spent two solid months arguing tha...      19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.DataFrame({'data': test.data, 'target': test.target})\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6c981",
   "metadata": {},
   "source": [
    "Text Processing: Cleaning punctuations, Removing Stop words, Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "077dbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8343b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "more_stopwords = ['u', 'im', 'c']\n",
    "stop_words = stop_words + more_stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c0cb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "def stemm_text(text):\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1c56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    # Clean puntuation, urls, and so on\n",
    "    text = clean_text(text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n",
    "    # Stemm all the words in the sentence\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e34b2255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>i was wondering if anyone out there could enli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>a fair number of brave souls who upgraded thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>well folks my mac plus finally gave up the gho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>do you have weiteks addressphone number  id li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>from article  by tombakerworldstdcom tom a bak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I was wondering if anyone out there could enli...       7   \n",
       "1  A fair number of brave souls who upgraded thei...       4   \n",
       "2  well folks, my mac plus finally gave up the gh...       4   \n",
       "3  \\nDo you have Weitek's address/phone number?  ...       1   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...      14   \n",
       "\n",
       "                                             clean_d  \n",
       "0  i was wondering if anyone out there could enli...  \n",
       "1  a fair number of brave souls who upgraded thei...  \n",
       "2  well folks my mac plus finally gave up the gho...  \n",
       "3  do you have weiteks addressphone number  id li...  \n",
       "4  from article  by tombakerworldstdcom tom a bak...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['clean_d'] = train1['data'].apply(clean_text)\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56f22ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>wondering anyone could enlighten car sawthe da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>fair number brave souls upgraded si clock osci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>well folks mac plus finally gave ghost weekend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>weiteks addressphone number  id like get infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>article  tombakerworldstdcom tom bakermy under...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I was wondering if anyone out there could enli...       7   \n",
       "1  A fair number of brave souls who upgraded thei...       4   \n",
       "2  well folks, my mac plus finally gave up the gh...       4   \n",
       "3  \\nDo you have Weitek's address/phone number?  ...       1   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...      14   \n",
       "\n",
       "                                             clean_d  \n",
       "0  wondering anyone could enlighten car sawthe da...  \n",
       "1  fair number brave souls upgraded si clock osci...  \n",
       "2  well folks mac plus finally gave ghost weekend...  \n",
       "3  weiteks addressphone number  id like get infor...  \n",
       "4  article  tombakerworldstdcom tom bakermy under...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['clean_d'] = train1['clean_d'].apply(remove_stopwords)\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc8a4995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>wonder anyon could enlighten car sawth day  sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>fair number brave soul upgrad si clock oscil h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>well folk mac plus final gave ghost weekend af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>weitek addressphon number  id like get informa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>articl  tombakerworldstdcom tom bakermi unders...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I was wondering if anyone out there could enli...       7   \n",
       "1  A fair number of brave souls who upgraded thei...       4   \n",
       "2  well folks, my mac plus finally gave up the gh...       4   \n",
       "3  \\nDo you have Weitek's address/phone number?  ...       1   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...      14   \n",
       "\n",
       "                                             clean_d  \n",
       "0  wonder anyon could enlighten car sawth day  sp...  \n",
       "1  fair number brave soul upgrad si clock oscil h...  \n",
       "2  well folk mac plus final gave ghost weekend af...  \n",
       "3  weitek addressphon number  id like get informa...  \n",
       "4  articl  tombakerworldstdcom tom bakermi unders...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['clean_d'] = train1['clean_d'].apply(stemm_text)\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8f9e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>wonder anyon could enlighten car sawth day  sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>fair number brave soul upgrad si clock oscil h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>well folk mac plus final gave ghost weekend af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>weitek addressphon number  id like get informa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>articl  tombakerworldstdcom tom bakermi unders...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I was wondering if anyone out there could enli...       7   \n",
       "1  A fair number of brave souls who upgraded thei...       4   \n",
       "2  well folks, my mac plus finally gave up the gh...       4   \n",
       "3  \\nDo you have Weitek's address/phone number?  ...       1   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...      14   \n",
       "\n",
       "                                             clean_d  \n",
       "0  wonder anyon could enlighten car sawth day  sp...  \n",
       "1  fair number brave soul upgrad si clock oscil h...  \n",
       "2  well folk mac plus final gave ghost weekend af...  \n",
       "3  weitek addressphon number  id like get informa...  \n",
       "4  articl  tombakerworldstdcom tom bakermi unders...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['clean_d'] = train1['clean_d'].apply(preprocess_data)\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63353ae",
   "metadata": {},
   "source": [
    "Performing same text processing and cleaning on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7498f417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "      <td>i am a little confused on all of the models of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>5</td>\n",
       "      <td>im not familiar at all with the format of thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIn a word, yes.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>in a word yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
       "      <td>17</td>\n",
       "      <td>they were attacking the iraqis to drive them o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
       "      <td>19</td>\n",
       "      <td>ive just spent two solid months arguing that n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I am a little confused on all of the models of...       7   \n",
       "1  I'm not familiar at all with the format of the...       5   \n",
       "2                                \\nIn a word, yes.\\n       0   \n",
       "3  \\nThey were attacking the Iraqis to drive them...      17   \n",
       "4  \\nI've just spent two solid months arguing tha...      19   \n",
       "\n",
       "                                             clean_d  \n",
       "0  i am a little confused on all of the models of...  \n",
       "1  im not familiar at all with the format of thes...  \n",
       "2                                      in a word yes  \n",
       "3  they were attacking the iraqis to drive them o...  \n",
       "4  ive just spent two solid months arguing that n...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1['clean_d'] = test1['data'].apply(clean_text)\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f63b25d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "      <td>little confused models  bonnevillesi heard le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>5</td>\n",
       "      <td>familiar format xface thingies butafter seeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIn a word, yes.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>word yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
       "      <td>17</td>\n",
       "      <td>attacking iraqis drive kuwaita country whose c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
       "      <td>19</td>\n",
       "      <td>ive spent two solid months arguing thing anobj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I am a little confused on all of the models of...       7   \n",
       "1  I'm not familiar at all with the format of the...       5   \n",
       "2                                \\nIn a word, yes.\\n       0   \n",
       "3  \\nThey were attacking the Iraqis to drive them...      17   \n",
       "4  \\nI've just spent two solid months arguing tha...      19   \n",
       "\n",
       "                                             clean_d  \n",
       "0  little confused models  bonnevillesi heard le ...  \n",
       "1  familiar format xface thingies butafter seeing...  \n",
       "2                                           word yes  \n",
       "3  attacking iraqis drive kuwaita country whose c...  \n",
       "4  ive spent two solid months arguing thing anobj...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1['clean_d'] = test1['clean_d'].apply(remove_stopwords)\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5337fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "      <td>littl confus model  bonnevillesi heard le se l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>5</td>\n",
       "      <td>familiar format xface thingi butaft see folk h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIn a word, yes.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>word yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
       "      <td>17</td>\n",
       "      <td>attack iraqi drive kuwaita countri whose citiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
       "      <td>19</td>\n",
       "      <td>ive spent two solid month argu thing anobject ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I am a little confused on all of the models of...       7   \n",
       "1  I'm not familiar at all with the format of the...       5   \n",
       "2                                \\nIn a word, yes.\\n       0   \n",
       "3  \\nThey were attacking the Iraqis to drive them...      17   \n",
       "4  \\nI've just spent two solid months arguing tha...      19   \n",
       "\n",
       "                                             clean_d  \n",
       "0  littl confus model  bonnevillesi heard le se l...  \n",
       "1  familiar format xface thingi butaft see folk h...  \n",
       "2                                           word yes  \n",
       "3  attack iraqi drive kuwaita countri whose citiz...  \n",
       "4  ive spent two solid month argu thing anobject ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1['clean_d'] = test1['clean_d'].apply(stemm_text)\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32660677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "      <td>littl confus model  bonnevillesi heard le se l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>5</td>\n",
       "      <td>familiar format xface thingi butaft see folk h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIn a word, yes.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>word yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThey were attacking the Iraqis to drive them...</td>\n",
       "      <td>17</td>\n",
       "      <td>attack iraqi drive kuwaita countri whose citiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI've just spent two solid months arguing tha...</td>\n",
       "      <td>19</td>\n",
       "      <td>ive spent two solid month argu thing anobject ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target  \\\n",
       "0  I am a little confused on all of the models of...       7   \n",
       "1  I'm not familiar at all with the format of the...       5   \n",
       "2                                \\nIn a word, yes.\\n       0   \n",
       "3  \\nThey were attacking the Iraqis to drive them...      17   \n",
       "4  \\nI've just spent two solid months arguing tha...      19   \n",
       "\n",
       "                                             clean_d  \n",
       "0  littl confus model  bonnevillesi heard le se l...  \n",
       "1  familiar format xface thingi butaft see folk h...  \n",
       "2                                           word yes  \n",
       "3  attack iraqi drive kuwaita countri whose citiz...  \n",
       "4  ive spent two solid month argu thing anobject ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1['clean_d'] = test1['clean_d'].apply(preprocess_data)\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b71666a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= train1['clean_d']\n",
    "y= train1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6bc8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "xte = test1['clean_d']\n",
    "yte = test1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2037903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(x)\n",
    "train2 = vect.transform(x)\n",
    "test2 = vect.transform(xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b10b3818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x125743 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 709980 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_transformer.fit(train2)\n",
    "train3 = tfidf_transformer.transform(train2)\n",
    "\n",
    "train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb7ea4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7532x125743 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 398095 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_transformer.fit(test2)\n",
    "test3 = tfidf_transformer.transform(test2)\n",
    "\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee2f5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train1['clean_d']\n",
    "target = train1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5301517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125807"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(texts)\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c499acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   404,     56,     17, ...,      0,      0,      0],\n",
       "       [   594,     52,   1892, ...,      0,      0,      0],\n",
       "       [    26,   1053,    327, ...,      0,      0,      0],\n",
       "       ...,\n",
       "       [   392,   1403,   2524, ...,      0,      0,      0],\n",
       "       [   507,    149, 125800, ...,      0,      0,      0],\n",
       "       [  2458,   5921,   1422, ...,      0,      0,      0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed(corpus): \n",
    "    return word_tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "longest_train = max(texts, key=lambda sentence: len(word_tokenize(sentence)))\n",
    "length_long_sentence = len(word_tokenize(longest_train))\n",
    "\n",
    "train_padded_sentences = pad_sequences(\n",
    "    embed(texts), \n",
    "    length_long_sentence, \n",
    "    padding='post'\n",
    ")\n",
    "\n",
    "train_padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73806a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "595ad535",
   "metadata": {},
   "source": [
    "Create a Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d5943c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb.fit(train3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26b16ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class and probability predictions\n",
    "y_pred_class = nb.predict(test3)\n",
    "y_pred_prob = nb.predict_proba(test3)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9930619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6315719596388741\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(yte, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0607c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('bow', CountVectorizer()), \n",
    "                 ('tfid', TfidfTransformer()),  \n",
    "                 ('model', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a5249f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.633563462559745\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline with the data\n",
    "pipe.fit(x, y)\n",
    "\n",
    "y_pred_class = pipe.predict(xte)\n",
    "\n",
    "print(metrics.accuracy_score(yte, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "134005e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dictionary = dict()\n",
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        \n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82c95cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 7058, 100)         12580700  \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 100)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100)              400       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7058)              712858    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7058)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7059      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,301,017\n",
      "Trainable params: 13,300,817\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def glove_lstm():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(\n",
    "        input_dim=embedding_matrix.shape[0], \n",
    "        output_dim=embedding_matrix.shape[1], \n",
    "        weights = [embedding_matrix], \n",
    "        input_length=length_long_sentence\n",
    "    ))\n",
    "    \n",
    "    #     model.add(Bidirectional(LSTM(\n",
    "#         length_long_sentence, \n",
    "#         return_sequences = True, \n",
    "#         recurrent_dropout=0.2\n",
    "#     )))\n",
    "    \n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = glove_lstm()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d70e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_padded_sentences, \n",
    "    target, \n",
    "    test_size=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "837cc6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6af139db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.0493\n",
      "Epoch 1: val_loss improved from inf to 0.45881, saving model to modellstm.h5\n",
      "19/19 [==============================] - 3s 125ms/step - loss: 0.5602 - accuracy: 0.0493 - val_loss: 0.4588 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.0495\n",
      "Epoch 2: val_loss improved from 0.45881 to 0.29130, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 120ms/step - loss: 0.3693 - accuracy: 0.0495 - val_loss: 0.2913 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.0495\n",
      "Epoch 3: val_loss improved from 0.29130 to 0.12853, saving model to modellstm.h5\n",
      "19/19 [==============================] - 3s 161ms/step - loss: 0.1995 - accuracy: 0.0495 - val_loss: 0.1285 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.0495\n",
      "Epoch 4: val_loss improved from 0.12853 to -0.03383, saving model to modellstm.h5\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.0317 - accuracy: 0.0495 - val_loss: -0.0338 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -0.1358 - accuracy: 0.0495\n",
      "Epoch 5: val_loss improved from -0.03383 to -0.19594, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 124ms/step - loss: -0.1358 - accuracy: 0.0495 - val_loss: -0.1959 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -0.3032 - accuracy: 0.0495\n",
      "Epoch 6: val_loss improved from -0.19594 to -0.35790, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 119ms/step - loss: -0.3032 - accuracy: 0.0495 - val_loss: -0.3579 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -0.4701 - accuracy: 0.0495\n",
      "Epoch 7: val_loss improved from -0.35790 to -0.51942, saving model to modellstm.h5\n",
      "19/19 [==============================] - 3s 143ms/step - loss: -0.4701 - accuracy: 0.0495 - val_loss: -0.5194 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -0.6374 - accuracy: 0.0495\n",
      "Epoch 8: val_loss improved from -0.51942 to -0.68152, saving model to modellstm.h5\n",
      "19/19 [==============================] - 3s 136ms/step - loss: -0.6374 - accuracy: 0.0495 - val_loss: -0.6815 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -0.8043 - accuracy: 0.0495\n",
      "Epoch 9: val_loss improved from -0.68152 to -0.84311, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 118ms/step - loss: -0.8043 - accuracy: 0.0495 - val_loss: -0.8431 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -0.9711 - accuracy: 0.0495\n",
      "Epoch 10: val_loss improved from -0.84311 to -1.00458, saving model to modellstm.h5\n",
      "19/19 [==============================] - 3s 181ms/step - loss: -0.9711 - accuracy: 0.0495 - val_loss: -1.0046 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -1.1376 - accuracy: 0.0495\n",
      "Epoch 11: val_loss improved from -1.00458 to -1.16570, saving model to modellstm.h5\n",
      "19/19 [==============================] - 3s 167ms/step - loss: -1.1376 - accuracy: 0.0495 - val_loss: -1.1657 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -1.3046 - accuracy: 0.0495\n",
      "Epoch 12: val_loss improved from -1.16570 to -1.32769, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 128ms/step - loss: -1.3046 - accuracy: 0.0495 - val_loss: -1.3277 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -1.4712 - accuracy: 0.0495\n",
      "Epoch 13: val_loss improved from -1.32769 to -1.48842, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 119ms/step - loss: -1.4712 - accuracy: 0.0495 - val_loss: -1.4884 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -1.6373 - accuracy: 0.0495\n",
      "Epoch 14: val_loss improved from -1.48842 to -1.64943, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 120ms/step - loss: -1.6373 - accuracy: 0.0495 - val_loss: -1.6494 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -1.8041 - accuracy: 0.0495\n",
      "Epoch 15: val_loss improved from -1.64943 to -1.81124, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 119ms/step - loss: -1.8041 - accuracy: 0.0495 - val_loss: -1.8112 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -1.9707 - accuracy: 0.0495\n",
      "Epoch 16: val_loss improved from -1.81124 to -1.97231, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 119ms/step - loss: -1.9707 - accuracy: 0.0495 - val_loss: -1.9723 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -2.1366 - accuracy: 0.0495\n",
      "Epoch 17: val_loss improved from -1.97231 to -2.13297, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 121ms/step - loss: -2.1366 - accuracy: 0.0495 - val_loss: -2.1330 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -2.3028 - accuracy: 0.0495\n",
      "Epoch 18: val_loss improved from -2.13297 to -2.29386, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 121ms/step - loss: -2.3028 - accuracy: 0.0495 - val_loss: -2.2939 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -2.4689 - accuracy: 0.0495\n",
      "Epoch 19: val_loss improved from -2.29386 to -2.45459, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 120ms/step - loss: -2.4689 - accuracy: 0.0495 - val_loss: -2.4546 - val_accuracy: 0.0636 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - ETA: 0s - loss: -2.6350 - accuracy: 0.0495\n",
      "Epoch 20: val_loss improved from -2.45459 to -2.61540, saving model to modellstm.h5\n",
      "19/19 [==============================] - 2s 119ms/step - loss: -2.6350 - accuracy: 0.0495 - val_loss: -2.6154 - val_accuracy: 0.0636 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model_lstm = glove_lstm()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'modellstm.h5', \n",
    "    monitor = 'val_loss', \n",
    "    verbose = 1, \n",
    "    save_best_only = True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss', \n",
    "    factor = 0.2, \n",
    "    verbose = 1, \n",
    "    patience = 5,                        \n",
    "    min_lr = 0.001\n",
    ")\n",
    "history = model_lstm.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs = 20,\n",
    "    batch_size = 512,\n",
    "    validation_data = (X_test, y_test),\n",
    "    verbose = 1,\n",
    "    callbacks = [reduce_lr, checkpoint]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
